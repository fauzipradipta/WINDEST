# -*- coding: utf-8 -*-
"""windner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f1_I5n_XQRxcwn0_2FQdRdFFg12iKjD8
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd content/drive/My\ Drive

import pandas as pd
import numpy as np
from google.colab import files
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import RepeatedKFold
import os
import io

wind_speed_df = pd.read_csv('wind_speed.csv')

wind_speed_df = wind_speed_df.dropna()

# Create Month column

wind_speed_df['Month'] = [str(datetime).split('-')[1] for datetime in wind_speed_df['datetime']]

# Create Day column

wind_speed_df['Day'] = [str(datetime).split('-')[2].split()[0] for datetime in wind_speed_df['datetime']]

wind_speed_df

# Create Year column

wind_speed_df['Year'] = [str(datetime).split('-')[0] for datetime in wind_speed_df['datetime']]

# Create Time column

wind_speed_df['Time'] = [str(datetime).split('-')[2].split()[1].split(':')[0] for datetime in wind_speed_df['datetime']]

# Drop non-US cities

wind_speed_df = wind_speed_df.drop('Jerusalem',axis=1)
wind_speed_df = wind_speed_df.drop('Nahariyya',axis=1)
wind_speed_df = wind_speed_df.drop('Haifa',axis=1)
wind_speed_df = wind_speed_df.drop('Eilat',axis=1)
wind_speed_df = wind_speed_df.drop('Tel Aviv District',axis=1)
wind_speed_df = wind_speed_df.drop('Beersheba',axis=1)
wind_speed_df = wind_speed_df.drop('Montreal',axis=1)
wind_speed_df = wind_speed_df.drop('Toronto',axis=1)

wind_speed_df = wind_speed_df.drop('datetime', axis = 1)
# cities_only = cities_only.drop('Month', axis = 1)

# Make sure to check for type of input being passed in (expected is String for all parameters)
import scipy.spatial.distance as distance

def predictWindSpeed(city, month, day):
  filtered_df = wind_speed_df[[city, 'Month', 'Day', 'Year', 'Time']].copy()
  filtered_df = filtered_df[filtered_df['Month'] == month]
  filtered_df = filtered_df[filtered_df['Day'] == day]

  x = filtered_df.drop(city, axis=1)
  y = filtered_df[city]

  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

  ### Normalization using standard scaler
  standardscaler = StandardScaler()
  standardscaler.fit(x_train)

  x_train_scale = standardscaler.fit_transform(x_train)

  def chi_square_distance(X, Y):
    with np.errstate(divide="ignore", invalid="ignore"):
        return (1 / 2) * np.sum(np.nan_to_num((np.square(X - Y) / (X + Y))))

  n_neighbors = [int(x) for x in np.linspace(23, 69, num = 37)]
  metric = [chi_square_distance, distance.euclidean]
  param_distribs = {'n_neighbors':n_neighbors,'metric': metric}
  estimator = KNeighborsRegressor()

  skfold = RepeatedKFold(n_splits=10,n_repeats=10,random_state=1)
  grid_search = GridSearchCV(estimator, param_distribs, n_jobs=5,cv=skfold)

  grid_search.fit(x_train_scale,y_train)
  best_model = grid_search.best_estimator_
  # Create a df from the cv_resutls
  df_cv = pd.DataFrame(grid_search.cv_results_)

  return best_model, df_cv

model, df_cv = predictWindSpeed('Boston', "10", "10")

#Input is a list of months that the user is interested in. Month is written in numbers, such as 10 for October.

def getBestWindfarms(months):
  windSpeeds = {}
  if months == "All":
    for city in cities_only.columns:
      windSpeeds[city] = sum(cities_only[city])
    sort_windSpeeds = sorted(windSpeeds.items(), key=lambda x: x[1], reverse=True)
  for i in sort_windSpeeds:
  	print(i[0], i[1])
  else:
    selected_months = cities_only['Month' in months]



