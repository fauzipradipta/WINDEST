{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelCreation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_-1tsAotxN",
        "outputId": "f9cf6b6b-ae23-4484-a65a-f9437e6f52dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jwcbDwJBIS8",
        "outputId": "8bc59628-b12f-4886-fb62-89862b0970c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xhIcgP7dsQd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oksjZpEX53t"
      },
      "source": [
        "wind_speed_df = pd.read_csv('wind_speed.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOeDm-cXZDqX"
      },
      "source": [
        "wind_speed_df = wind_speed_df.dropna()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5meb53BGtDI"
      },
      "source": [
        "# Create Month column\n",
        "\n",
        "wind_speed_df['Month'] = [str(datetime).split('-')[1] for datetime in wind_speed_df['datetime']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiL0DtJTxf96"
      },
      "source": [
        "# Create Day column\n",
        "\n",
        "wind_speed_df['Day'] = [str(datetime).split('-')[2].split()[0] for datetime in wind_speed_df['datetime']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPKd04ozPqdJ"
      },
      "source": [
        "# Create Year column\n",
        "\n",
        "wind_speed_df['Year'] = [str(datetime).split('-')[0] for datetime in wind_speed_df['datetime']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67U61RkbQBhL"
      },
      "source": [
        "# Create Time column\n",
        "\n",
        "wind_speed_df['Time'] = [str(datetime).split('-')[2].split()[1].split(':')[0] for datetime in wind_speed_df['datetime']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3cQ1fp_Zr6c"
      },
      "source": [
        "# Drop non-US cities\n",
        "\n",
        "wind_speed_df = wind_speed_df.drop('Jerusalem',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Nahariyya',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Haifa',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Eilat',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Tel Aviv District',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Beersheba',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Montreal',axis=1)\n",
        "wind_speed_df = wind_speed_df.drop('Toronto',axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egoyeHpndSD9"
      },
      "source": [
        "wind_speed_df = wind_speed_df.drop('datetime', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ04_zLPvxBb"
      },
      "source": [
        "#Store cleaned data in file to restore for later use\n",
        "import pickle\n",
        "\n",
        "with open('cleanedData.pkl', 'wb') as f:\n",
        "  pickle.dump(wind_speed_df, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmMbjU6Szp8-"
      },
      "source": [
        "# Make sure to check for type of input being passed in (expected is String for all parameters)\n",
        "import scipy.spatial.distance as distance\n",
        "\n",
        "def getModel(x, y):\n",
        "  def chi_square_distance(X, Y):\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        return (1 / 2) * np.sum(np.nan_to_num((np.square(X - Y) / (X + Y))))\n",
        "\n",
        "  n_neighbors = [int(x) for x in np.linspace(23, 69, num = 37)]\n",
        "  metric = [chi_square_distance, distance.euclidean, distance.minkowski, distance.cosine]\n",
        "  param_distribs = {'n_neighbors':n_neighbors,'metric': metric}\n",
        "  estimator = KNeighborsRegressor()\n",
        "\n",
        "  skfold = RepeatedKFold(n_splits=10,n_repeats=10,random_state=1)\n",
        "  grid_search = GridSearchCV(estimator, param_distribs, n_jobs=5,cv=skfold)\n",
        "\n",
        "  grid_search.fit(x,y)\n",
        "  best_model = grid_search.best_estimator_\n",
        "\n",
        "  # Create a df from the cv_resutls\n",
        "  df_cv = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "  return best_model, df_cv"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCZk52jDoPok"
      },
      "source": [
        "def filterWithUserInput(city, month, day):\n",
        "  filtered_df = wind_speed_df[[city, 'Month', 'Day', 'Year', 'Time']].copy()\n",
        "  filtered_df = filtered_df[filtered_df['Month'] == month]\n",
        "  filtered_df = filtered_df[filtered_df['Day'] == day]\n",
        "\n",
        "  x = filtered_df.drop(city, axis=1)\n",
        "  y = filtered_df[city]\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  ### Normalization using standard scaler\n",
        "  standardscaler = StandardScaler()\n",
        "  standardscaler.fit(x_train)\n",
        "\n",
        "  x_train_scale = standardscaler.fit_transform(x_train)\n",
        "\n",
        "  model, df_cv = getModel(x_train_scale, y_train)\n",
        "\n",
        "  #Retrain on training set\n",
        "  model.fit(x_train_scale,y_train)\n",
        "\n",
        "  ### Normalization using standard scaler for test\n",
        "  standardscaler = StandardScaler()\n",
        "  standardscaler.fit(x_test)\n",
        "\n",
        "  x_test_scale = standardscaler.fit_transform(x_test)\n",
        "\n",
        "  return model, df_cv, x_train_scale, y_train, x_test_scale, y_test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsyL9rJ5gNw-"
      },
      "source": [
        "model, df_cv, x_train_scale, y_train, x_test_scale, y_test = filterWithUserInput('Boston', \"10\", \"1\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TP7nY6g7rtc",
        "outputId": "3570f246-a5ea-4b57-bdfc-a0a7c91ac880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import statistics\n",
        "\n",
        "# Average difference between prediction and actual value (using the test dataset)\n",
        "prediction = model.predict(x_test_scale)\n",
        "print(\"Average difference between prediction and actual value:\", sum(abs(prediction - y_test))/115)\n",
        "print(\"Median difference:\", statistics.median(abs(prediction - y_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average difference between prediction and actual value: 0.4992236024844721\n",
            "Median difference: 1.6964285714285712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsy4U0FbKMd7"
      },
      "source": [
        "#Store model in file to restore for later use\n",
        "import pickle\n",
        "\n",
        "with open('model.pkl', 'wb') as f:\n",
        "  pickle.dump(model, f)"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}